{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "# The Chambolle-Pock Primal-Dual Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "**STANGELAND Aleksander (5GMM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "import pywt\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import param\n",
    "import panel as pn\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from panel.pane import LaTeX\n",
    "hv.extension('bokeh')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from numpy.fft import fft2, ifft2, fftshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## General problem\n",
    "\n",
    "This algorithm is a first-order primal-dual algorithm used to solve convex optimization problems with known saddle-point structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "Let $X$, $Y$ be two finite-dimensional real vector spaces equipped with an inner\n",
    "product $\\langle ·,· \\rangle$, and norm $||·|| = \\langle ·,· \\rangle^{\\frac{1}{2}}$. The map $K : X \\to Y$ is a continuous\n",
    "linear operator with induced norm\n",
    "\n",
    "$$||K|| = \\textrm{max}\\{ ||K||: x\\in X \\;\\; \\textrm{with} \\;\\; ||x|| \\leq 1\\}$$\n",
    "\n",
    "The general problem we consider in this paper is the generic saddle-point problem\n",
    "\n",
    "$$\\min_{x\\in X}\\max_{y \\in Y} \\langle Kx,y \\rangle + G(x) -F^*(y)$$\n",
    "\n",
    "where $G:X\\to[0,+\\infty)$ and $F^*:Y\\to[0,+\\infty)$ are proper, convex, lowersemicontinuous (l.s.c.) functions, $F^*$ being itself the convex conjugate of a convex l.s.c. function $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "The saddle-point problem is primal-dual formulation of the nonlinear primal problem\n",
    "\n",
    "$$\\min_{x\\in X} F(Kx) + G(x)$$\n",
    "\n",
    "or of the corresponding dual problem\n",
    "$$\\max_{y \\in Y} - ( G^*(-K^*y) + F^*(y) )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "**Algorithm 1**\n",
    "\n",
    "Initialization: choose $\\tau$, $\\sigma > 0$, $(x_0,y_0)\\in X\\times Y$ and set $\\bar{x}_0 = x_0$.\n",
    "\n",
    "Iterations $(n \\geq 0)$: Update $x_n$, $y_n$, $\\bar{x}_n$ as follows:\n",
    "\n",
    "$$\\begin{cases}\n",
    "y_{n+1} = \\textrm{prox}_{\\sigma F^*} (y_n +\\sigma K \\bar{x}_n) \\\\\n",
    "x_{n+1} = \\textrm{prox}_{\\tau G} (x_n - \\tau K^* y_{n+1}) \\\\\n",
    "\\bar{x}_{n+1} = x_{n+1} -x_n\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "Data are available online but if you have downloaded them, you can work online changing the value of the variable \"local\" in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def chargeData(name):\n",
    "    if name=='Lenna':\n",
    "        url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/Lenna.jpg'        \n",
    "        response = requests.get(url)\n",
    "        res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "    if name=='Canaletto':\n",
    "        url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/Canaletto.jpeg'\n",
    "        response = requests.get(url)\n",
    "        res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "    if name=='LennaMasked':\n",
    "        url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/LennaMasked50.png'        \n",
    "        response = requests.get(url)\n",
    "        res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "    if name=='LennaInpainted':\n",
    "        url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/LennaInpainted50.png'        \n",
    "        response = requests.get(url)\n",
    "        res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "im1,im2 =chargeData('Lenna'),chargeData('Canaletto')\n",
    "imagesRef= {\"Lenna\" : im1,\"Canaletto\" : im2}\n",
    "optionsRGB=dict(width=300,height=300,xaxis=None,yaxis=None,toolbar=None)\n",
    "optionsGray=dict(cmap='gray',width=300,height=300,xaxis=None,yaxis=None,toolbar=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "# Total variation based image denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "In order to evaluate and compare the performance of the proposed primal-dual algorithm to state-of-the-art methods, we consider three different convex image denoising models, each having a different degree of regularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "**Noising function and PSNR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def PSNR(I,Iref):\n",
    "    temp=I.ravel()\n",
    "    tempref=Iref.ravel()\n",
    "    NbP=I.size\n",
    "    EQM=np.sum((temp-tempref)**2)/NbP\n",
    "    b=np.max(np.abs(tempref))**2\n",
    "    return 10*np.log10(b/EQM)\n",
    "\n",
    "def Noise(I,seednoise,s):\n",
    "    N=np.shape(I)[0]\n",
    "    np.random.seed(seed=seednoise)\n",
    "    \n",
    "    noise=np.random.randn(N,N)\n",
    "    IB=I+mu*noise\n",
    "    \n",
    "    IB = np.clip(IB,0,255)\n",
    "    return IB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "I = imagesRef['Lenna'].astype('uint8')\n",
    "seednoise = 1\n",
    "mu = 10\n",
    "IB = Noise(I,seednoise,mu)\n",
    "psnr = PSNR(IB,I)\n",
    "print('PSNR:',psnr)\n",
    "pn.Row(hv.Image(I).opts(**optionsGray).relabel('Référence'),hv.Image(IB).opts(**optionsGray).relabel('Image bruitée'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "To use the gradient $\\nabla u$ in the discrete case, we use standard finite differences with Neumann boundary conditions:\n",
    "\n",
    "$$(\\nabla u)_{i,j} = \\begin{pmatrix}\n",
    "(\\nabla u)_{i,j}^1 \\\\\n",
    "(\\nabla u)_{i,j}^2\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "where \n",
    "\n",
    "$$(\\nabla u)_{i,j}^1 = \\begin{cases}\n",
    "\\frac{u_{i+1,j} - u_{i,j}}{h} & \\textrm{if} \\;\\; i<M \\\\\n",
    "0 & \\textrm{if} \\;\\; i=M\n",
    "\\end{cases}, \\;\\;\\;\\; (\\nabla u)_{i,j}^2 = \\begin{cases}\n",
    "\\frac{u_{i,j+1} - u_{i,j}}{h} & \\textrm{if} \\;\\; i<N \\\\\n",
    "0 & \\textrm{if} \\;\\; i=N\n",
    "\\end{cases}$$\n",
    "\n",
    "Here, $h=1$.\n",
    "\n",
    "We also calculate the conjugate gradient using the fact that $-\\textrm{div} = \\nabla^*$.\n",
    "\n",
    "Finally, we find that the bound of the norm of the gradient $\\nabla$ is\n",
    "\n",
    "$$L^2 = ||\\nabla||^2 = ||\\textrm{div}||^2 \\leq \\frac{8}{h^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def dx(im) :\n",
    "    d=np.zeros(np.shape(im))\n",
    "    d[:-1,:]=im[1:,:]-im[:-1,:]\n",
    "    return d\n",
    "\n",
    "def dy(im) :\n",
    "    d=np.zeros(np.shape(im))\n",
    "    d[:,:-1]=im[:,1:]-im[:,:-1]\n",
    "    return d\n",
    "\n",
    "def grad(im):\n",
    "    m,n = np.shape(im)\n",
    "    res = np.zeros((m,n,2))\n",
    "    res[:,:,0] = dx(im)\n",
    "    res[:,:,1] = dy(im)\n",
    "    return res\n",
    "    \n",
    "def grad_ad(p):\n",
    "    m,n,l = np.shape(p)\n",
    "    res = np.zeros((m,n))\n",
    "    res[0,0] = -p[0,0,0] -p[0,0,1]\n",
    "    res[-1,0] = p[-2,0,0] -p[-1,0,1]\n",
    "    res[0,-1] = -p[0,-1,0] +p[0,-2,1]\n",
    "    res[-1,-1] = p[-2,-1,0] +p[-1,-2,1]\n",
    "    res[1:-1,0] = p[:-2,0,0] -p[1:-1,0,0] -p[1:-1,0,1]\n",
    "    res[1:-1,-1] = p[:-2,-1,0] -p[1:-1,-1,0] +p[1:-1,-2,1]\n",
    "    res[0,1:-1] = p[0,:-2,1] -p[0,1:-1,1] -p[0,1:-1,0]\n",
    "    res[-1,1:-1] = p[-1,:-2,1] -p[-1,1:-1,1] +p[-2,1:-1,0]\n",
    "    res[1:-1,1:-1] = p[:-2,1:-1,0] -p[1:-1,1:-1,0] +p[1:-1,:-2,1] -p[1:-1,1:-1,1]\n",
    "    return res\n",
    "    \n",
    "def scalar_prod(u,v): # works in X and Y\n",
    "    return np.sum(u*v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## The ROF model\n",
    "\n",
    "**Total variation based image denoising model** proposed by Rudin, Osher and Fatemi: <br>\n",
    "$$\\min_{ x} \\int_{\\Omega} | Du | + \\frac{\\lambda}{2} \\| u - g \\|_2^{2}$$\n",
    "\n",
    "where $\\Omega \\in \\mathbb{R}^{d}$ is the $d$-dimensional image domain, $u \\in L^1(\\Omega)$ is the sought solution and $g \\in L^1(\\Omega)$ is the noisy input image.\n",
    "\n",
    "The parameter $\\lambda$ is the regularization factor,  it defines the tradeoff between regularization and data fitting.\n",
    "\n",
    "$\\int_{\\Omega} | Du |$ is the total variation of $u$\n",
    "and $| Du |$ is the distributional derivative.\n",
    "\n",
    "**In discrete setting (dimension d=2)**, the discrete ROF model or primal ROF problem:\n",
    "$$h^{2} \\min_{u \\in X} \\|\\nabla u \\|_1 + \\frac{\\lambda}{2} \\| u - g \\|_2^{2}$$\n",
    "\n",
    "where $u \\in L^1(\\Omega)$ is the sought solution and $g \\in L^1(\\Omega)$ is the noisy input image.\n",
    "\n",
    "Advantage of the total variation and of the ROF model: \n",
    "Total variation preserves sharp edges in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "We see that $F(\\nabla u) = \\|\\nabla u\\|$ and $G(u) = \\frac{\\lambda}{2} \\| u - g \\|^2_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "The **Primal-dual formulation of the ROF problem** is given by \n",
    "\n",
    "$$h^2 \\min_{u \\in X}  \\max_{p \\in Y} - \\langle u, \\text{div } p \\rangle_X + \\frac{\\lambda}{2} \\|u-g\\|_2^{2} - \\delta_P(p)$$ \n",
    "where $p \\in Y$ is the dual variable. The convex set P is given by $P= \\{ p \\in Y: \\|p\\|_{ \\infty } \\leq 1 \\}$, and $\\|p\\|_{ \\infty}$ denotes the discrete maximum norm defined as\n",
    "\n",
    "$\\|p\\|_{ \\infty } = \\max_{i,j} |p_{i,j}|$,   $|p_{i,j}| = \\sqrt{ (p_{i,j}^1)^2 +(p_{i,j}^2)^2}$.\n",
    "\n",
    "The function $\\delta_{P}$ denotes the indicator function of the set $P$ which is defined as\n",
    "\n",
    "$\\delta_P(p) = \\begin{cases} 0 \\text{ if } p \\in P, \\\\ \\infty \\text{ if } p \\not \\in P. \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "**Operateurs proximaux**:\n",
    "\n",
    "$$ p =(I+ \\sigma \\partial F^*)^{-1} (\\bar p) \\Leftrightarrow p_{i,j} = \\frac{ \\bar p_{i,j}}{\\max(1,| \\bar p_{i,j} |)}$$\n",
    "$$ u =(I+ \\tau \\partial G)^{-1} (\\bar u) \\Leftrightarrow u_{i,j} = \\frac{\\bar u_{i,j} + \\tau \\lambda g_{i,j}}{1+ \\tau \\lambda}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def ChambollPock_Denoising(I, lamb, sigma, tau, theta=1, Niter=10000):\n",
    "    n,m = np.shape(I)\n",
    "\n",
    "    # Opérateurs proximaux\n",
    "    def prox_sig_F_ad(p):\n",
    "        den = p**2\n",
    "        den = (den[:,:,0] + den[:,:,1])**0.5\n",
    "        den = np.where(den < 1, 1, den)\n",
    "        den_2 = np.zeros(np.shape(p))\n",
    "        den_2[:,:,0] = den\n",
    "        den_2[:,:,1] = den\n",
    "        res = p/den_2\n",
    "        return res\n",
    "\n",
    "    def prox_tau_G(u,g,lam,tau):\n",
    "        res = (u + lam*tau*g)/(1+lam*tau)\n",
    "        return res\n",
    "\n",
    "    #Initialization\n",
    "    u = np.zeros((m,n))\n",
    "    p = np.zeros((m,n,2)) \n",
    "    u_bar = np.copy(u)\n",
    "    \n",
    "    it = 0\n",
    "    err = 1\n",
    "    err_iter = []\n",
    "    \n",
    "    while it < Niter and err > 1e-10 :\n",
    "        \n",
    "        p = prox_sig_F_ad(p+sigma*grad(u_bar))\n",
    "        u_prev = np.copy(u)\n",
    "        u = prox_tau_G(u-tau*grad_ad(p),I,lamb,tau)\n",
    "        u_bar_prev = np.copy(u_bar)\n",
    "        u_bar = u + theta*(u - u_prev)\n",
    "        err = npl.norm(u_bar - u_bar_prev)\n",
    "        \n",
    "        \n",
    "        it += 1\n",
    "        err_iter += [err]\n",
    "        \n",
    "    return u_bar, err_iter, it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    " **Choice of the parameters $L$, $\\sigma$, and $\\tau$**:\n",
    " \n",
    "$$ 0 < \\tau \\sigma \\leq \\frac{1}{L²}$$\n",
    "\n",
    "So, as in our case $h=1$, $\\tau$ and $\\sigma$ are chosen such as $$ 0 < \\tau \\sigma \\leq \\frac{1}{8}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class CPDenoising(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Lenna\",objects=imagesRef.keys())\n",
    "    Niter = param.Integer(1000,bounds=(1,10000))\n",
    "    seednoise = param.Number(1,bounds=(1,5))\n",
    "    mu = param.Number(10,bounds=(1,30))\n",
    "    lamb = param.Number(0.1,bounds=(0,10))\n",
    "    tau = param.Number(0.5,bounds=(0,10))\n",
    "    sigma = param.Number(0.25,bounds=(0,10))\n",
    "    \n",
    "    def view(self):\n",
    "        I = imagesRef[self.image].astype('uint8')\n",
    "        IB = Noise(I,self.seednoise,self.mu).astype('uint8')\n",
    "        \n",
    "        Irec,err,it=ChambollPock_Denoising(IB,self.lamb,self.sigma,self.tau,theta=1,Niter=self.Niter)\n",
    "        \n",
    "        p1=PSNR(IB,I)\n",
    "        p2=PSNR(Irec,I)\n",
    "        Image1 = hv.Image(I).opts(**optionsGray).relabel('Référence')\n",
    "        Image2 = hv.Image(IB).opts(**optionsGray).relabel('Image bruitée')\n",
    "        Image3 = hv.Image(Irec).opts(**optionsGray).relabel('Image débruitée')\n",
    "        return pn.Row(Image1,Image2,Image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "cpdenoising = CPDenoising()\n",
    "pn.Row(cpdenoising.param,cpdenoising.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "lamb = 0.1\n",
    "sigma = 0.25\n",
    "tau = 0.5\n",
    "\n",
    "Irec, error, it = ChambollPock_Denoising(IB,lamb,sigma,tau)\n",
    "print('PSNR(IB,IRef):',PSNR(IB,I))\n",
    "print('PSNR(Irec,IRef):',PSNR(Irec,I))\n",
    "print('Nb iterations:',it)\n",
    "plt.loglog()\n",
    "plt.plot(np.arange(it),error,color='red')\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel('iterations')\n",
    "plt.title(r'ROF:  $\\lambda = $'+str(lamb))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "The algorithm is supposed to converge in O(1/N)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## Acceleration\n",
    "\n",
    "In case either $G$ or $F^*$ is uniformly convex, such that $G^*$ or $F$ has a Lipschiptz continuous gradient, $O(\\frac{1}{N²})$ convergence can be guaranteed.\n",
    "\n",
    "In case both $G$ and $F^*$ are uniformly convex, linear convergence $O(\\frac{1}{\\exp^{N}})$ can be achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "**Algorithm 2**\n",
    "\n",
    "Initialization: Choose $\\tau_0,\\sigma_0 >0$ with $\\tau_0 \\sigma_0 L^2 \\leq 1$, $(x^0,y^0) \\in X \\times Y$, and $\\bar x^0 = x^0$.\n",
    "\n",
    "Iterations (n$ \\ge 0$): Update $x^n$,$y^n$,$\\bar x^n$, $\\theta_n, \\tau_n,\\sigma_n$ as follows:\n",
    "\n",
    "$$\\begin{cases}\n",
    "y^{n+1} = \\textrm{prox}_{\\sigma_n F^*} (y^n +\\sigma_n K \\bar{x}^n) \\\\\n",
    "x^{n+1} = \\textrm{prox}_{\\tau_n G} (x^n - \\tau_n K^* y^{n+1}) \\\\\n",
    "\\theta_n = 1/ \\sqrt{1+2 \\gamma \\tau_n} \\\\\n",
    "\\tau_{n+1} = \\theta_n \\tau_n \\\\\n",
    "\\sigma_{n+1} = \\sigma_n / \\theta_n \\\\\n",
    "\\bar{x}^{n+1} = x^{n+1} - \\theta_n (x^{n+1} - x^{n})\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    " **Choice of the parameters $L$, $\\sigma_0$, and $\\tau_0$**:\n",
    "\n",
    "So, as in our case $h=1$, $\\tau_0$ and $\\sigma_0$ are chosen such as $$ 0 < \\tau_0 \\sigma_0 \\leq \\frac{1}{8}.$$\n",
    "\n",
    "**Choice of the parameter $\\gamma$**:\n",
    "\n",
    "In the article the following value was proposed:\n",
    "$$\\gamma = 0.7\\tau.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## Application to the ROF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def ChambollPock_Accelerated(I,lamb,sigma,tau,gamma,Niter=10000):\n",
    "    n,m = np.shape(I)\n",
    "\n",
    "    # Opérateurs proximaux\n",
    "    def prox_sig_F_ad(p):\n",
    "        den = p**2\n",
    "        den = (den[:,:,0] + den[:,:,1])**0.5\n",
    "        den = np.where(den < 1, 1, den)\n",
    "        den_2 = np.zeros(np.shape(p))\n",
    "        den_2[:,:,0] = den\n",
    "        den_2[:,:,1] = den\n",
    "        res = p/den_2\n",
    "        return res\n",
    "\n",
    "    def prox_tau_G(u,g,lam,tau):\n",
    "        res = (u + lam*tau*g)/(1+lam*tau)\n",
    "        return res\n",
    "        \n",
    "    #Initialization\n",
    "    u = np.zeros((m,n))\n",
    "    p = np.zeros((m,n,2)) \n",
    "    u_bar = np.copy(u)\n",
    "    \n",
    "    it = 0\n",
    "    err = 1\n",
    "    err_iter = []\n",
    "    \n",
    "    while it < Niter and err > 1e-10 :\n",
    "        \n",
    "        p = prox_sig_F_ad(p+sigma*grad(u_bar))\n",
    "        u_prev = np.copy(u)\n",
    "        u = prox_tau_G(u-tau*grad_ad(p),I,lamb,tau)\n",
    "        u_bar_prev = np.copy(u_bar)\n",
    "        theta= 1/np.sqrt(1+2*gamma*tau) # gamma = 0.7*lamb ?\n",
    "        tau = theta*tau\n",
    "        sigma = sigma/theta\n",
    "        u_bar = u + theta*(u -u_prev)\n",
    "        \n",
    "        err = npl.norm(u_bar - u_bar_prev)\n",
    "        \n",
    "        it += 1\n",
    "        err_iter += [err]\n",
    "        \n",
    "    return u_bar, err_iter, it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class CPADenoising(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Lenna\",objects=imagesRef.keys())\n",
    "    Niter = param.Integer(100,bounds=(1,100))\n",
    "    seednoise = param.Number(1,bounds=(1,5))\n",
    "    mu = param.Number(10,bounds=(1,30))\n",
    "    lamb = param.Number(0.1,bounds=(0,1))\n",
    "    tau0 = param.Number(2.83,bounds=(0,3)) #2.83\n",
    "    sigma0 = param.Number(0.442,bounds=(0,1)) #0.442\n",
    "    \n",
    "    def view(self):\n",
    "        I = imagesRef[self.image].astype('uint8')\n",
    "        IB = Noise(I,self.seednoise,self.mu).astype('uint8')\n",
    "        \n",
    "        Irec,err,it=ChambollPock_Accelerated(IB,self.lamb,self.sigma0,self.tau0,gamma=0.7*self.lamb,Niter=self.Niter)\n",
    "        \n",
    "        \n",
    "        Image1 = hv.Image(I).opts(**optionsGray).relabel('Référence')\n",
    "        Image2 = hv.Image(IB).opts(**optionsGray).relabel('Image bruitée')\n",
    "        Image3 = hv.Image(Irec).opts(**optionsGray).relabel('Image débruitée')\n",
    "        return pn.Row(Image1,Image2,Image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "cpadenoising = CPADenoising()\n",
    "pn.Row(cpadenoising.param,cpadenoising.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "lamb = 0.1\n",
    "tau0 = 2.83\n",
    "sigma0 = 0.442\n",
    "gamma = 0.7*tau0\n",
    "Irec, error, it = ChambollPock_Accelerated(IB,lamb,sigma0,tau0,gamma)\n",
    "\n",
    "\n",
    "# Normalize images\n",
    "IB_norm = (IB-np.min(IB))/(np.max(IB)-np.min(IB))\n",
    "Irec_norm = (Irec-np.min(Irec))/(np.max(Irec)-np.min(Irec))\n",
    "I_norm = (I-np.min(I))/(np.max(I)-np.min(I))\n",
    "\n",
    "print('Remark: Images need to be normalized here')\n",
    "print('PSNR(IB,IRef):',PSNR(IB_norm,I_norm))\n",
    "print('PSNR(Irec,IRef):',PSNR(Irec_norm,I_norm))\n",
    "print(\"Number of iterations:\",it)\n",
    "plt.loglog()\n",
    "plt.plot(np.arange(it),error,color='red',label='Error')\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel('iterations')\n",
    "plt.legend()\n",
    "plt.title(r'ROF:  $\\lambda = $'+str(lamb))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## $T V-L^1$ model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "The $TV-L^1$ model is obtained as a variant of the ROF model by replacing the squared $L^2$ norm in the data term by the robust $L^1$ norm.\n",
    "\n",
    "$$\\min_{ x} \\int_{\\Omega} | Du | + \\frac{\\lambda}{2} \\| u - g \\|_1$$\n",
    "\n",
    "where $\\Omega \\in \\mathbb{R}^{d}$ is the $d$-dimensional image domain, $u \\in L^1(\\Omega)$ is the sought solution and $g \\in L^1(\\Omega)$ is the noisy input image.\n",
    "\n",
    "The parameter $\\lambda$ is the regularization factor,  it defines the tradeoff between regularization and data fitting.\n",
    "\n",
    "$\\int_{\\Omega} | Du |$ is the total variation of $u$\n",
    "and $| Du |$ is the distributional derivative.\n",
    "\n",
    "**In discrete setting (dimension d=2)**, the discrete ROF model or primal ROF problem:\n",
    "\n",
    "$$ \\min_{u \\in X} \\|\\nabla u \\|_1 + \\lambda \\| u - g \\|_1 $$\n",
    "\n",
    "where $u \\in L^1(\\Omega)$ is the sought solution and $g \\in L^1(\\Omega)$ is the noisy input image.\n",
    "\n",
    "Although only a slight change, the $TV-L^1$ model offers some potential advantages over the ROF model. First, one can check that it is contrast invariant. Second, it turns out that the $TV-L^1$ model is much more effective in removing noise containing strong outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "We see that $F(\\nabla u) = \\|\\nabla u\\|_1$ and $G(u) = \\lambda \\| u - g \\|_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "The **Primal-dual formulation of the $TV-L^1$ model** is given by \n",
    "\n",
    "$$ \\min_{u \\in X}  \\max_{p \\in Y} - \\langle u, \\text{div } p \\rangle_X + \\lambda \\|u-g\\|_1 - \\delta_P(p)$$ \n",
    "\n",
    "Comparing with the ROF problem, we see that the only difference is that the function $G(u)$ is now $G(u) = \\lambda \\| u - g \\|_1$\n",
    "\n",
    "The change of the proximal operator is :\n",
    "\n",
    "$$u =(I+ \\tau \\partial G)^{-1} (\\bar u) \\Leftrightarrow u_{i,j} =  \n",
    "\\begin{cases}{ll}\n",
    "    \\bar u _{i,j} - \\tau \\lambda & \\mbox{si } \\bar u _{i,j} - g_{i,j} \\gt \\tau \\lambda \\\\\n",
    "    \\bar u _{i,j} + \\tau \\lambda & \\mbox{si } \\bar u _{i,j} - g_{i,j} \\lt - \\tau \\lambda \\\\\n",
    "    g_{i,j} & \\mbox{si } | \\bar u _{i,j} - g_{i,j} | \\le  \\tau \\lambda \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Note that while the ROF leads to an over-regularized result, the $TV-L^1$ model efficiently removes the outliers while preserving small details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def TV_L1_Denoising(I,lamb,sigma,tau,theta = 1,Niter=10000):\n",
    "    \n",
    "    def prox_sig_F_ad(p):\n",
    "        den = p**2\n",
    "        den = (den[:,:,0] + den[:,:,1])**0.5\n",
    "        den = np.where(den < 1, 1, den)\n",
    "        den_2 = np.zeros(np.shape(p))\n",
    "        den_2[:,:,0] = den\n",
    "        den_2[:,:,1] = den\n",
    "        res = p/den_2\n",
    "        return res\n",
    "\n",
    "    def prox_tau_G(u,g,lam,tau):\n",
    "        tempug = u-g\n",
    "        ind1 = np.where(tempug > lam*tau)\n",
    "        ind2 = np.where(tempug < -lam*tau)  \n",
    "        ind3 = np.where(np.abs(tempug) <= lam*tau)\n",
    "        \n",
    "        res = np.zeros(np.shape(u))\n",
    "        \n",
    "        res[ind1] = u[ind1] - lam*tau\n",
    "        res[ind2] = u[ind2] + lam*tau\n",
    "        res[ind3] = g[ind3]\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    n,m = np.shape(I)\n",
    "    \n",
    "    #Initialisation (à revoir peut-être)\n",
    "    \n",
    "    u = np.zeros((m,n)) #Initialisation à 0 : convergence plus rapide que l'initialisation aléatoire\n",
    "    p = np.zeros((m,n,2)) \n",
    "    u_bar = np.copy(u)\n",
    "    \n",
    "    it = 0\n",
    "    err = 1\n",
    "    err_iter = []\n",
    "    \n",
    "    while it < Niter and err > 1e-10 :\n",
    "        \n",
    "        p = prox_sig_F_ad(p+sigma*grad(u_bar))\n",
    "        \n",
    "        u_prev = np.copy(u)\n",
    "        \n",
    "        u = prox_tau_G(u-tau*grad_ad(p),I,lamb,tau)\n",
    "        \n",
    "        u_bar_prev = np.copy(u_bar)\n",
    "        \n",
    "        u_bar = u + theta*(u -u_prev)\n",
    "        \n",
    "        err = npl.norm(u_bar - u_bar_prev)\n",
    "        \n",
    "        \n",
    "        it += 1\n",
    "        err_iter += [err]\n",
    "        \n",
    "    return u_bar, err_iter, it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def Noise_SaltPepper(I,seednoise,amount):\n",
    "    np.random.seed(seed=seednoise)\n",
    "    \n",
    "    IB = np.copy(I)\n",
    "    \n",
    "    s_vs_p = 0.5\n",
    "    # Salt mode\n",
    "    num_salt = np.ceil(amount * I.size * s_vs_p)\n",
    "    coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "          for i in I.shape]\n",
    "    IB[coords] = 255\n",
    "    # Pepper mode\n",
    "    num_pepper = np.ceil(amount* I.size * (1. - s_vs_p))\n",
    "    coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "          for i in I.shape]\n",
    "    IB[coords] = 0\n",
    "    \n",
    "    return IB\n",
    "\n",
    "seednoise = 1\n",
    "amount = 0.25\n",
    "IB = Noise_SaltPepper(I,seednoise,amount)\n",
    "\n",
    "pn.Row(hv.Image(I).opts(**optionsGray).relabel('Ref'),hv.Image(IB).opts(**optionsGray).relabel('Bruitée'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "lamb = 1.5\n",
    "Irec, error, it = TV_L1_Denoising(IB,lamb,1,0.5)\n",
    "print('PSNR(IB,IRef):',PSNR(IB,I))\n",
    "print('PSNR(Irec,IRef):',PSNR(Irec,I))\n",
    "plt.loglog()\n",
    "plt.plot(np.arange(it),error,color='black')\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel('iterations')\n",
    "plt.title(r'TV-L1:  $\\lambda = 1.5$')\n",
    "plt.show()\n",
    "pn.Row(hv.Image(I).opts(**optionsGray).relabel('Ref'),hv.Image(IB).opts(**optionsGray).relabel('Bruité'),hv.Image(Irec).opts(**optionsGray).relabel('Débruitée'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "lamb = 1.5\n",
    "IBn = Noise(I,1,10).astype('uint8')\n",
    "Irec, error, it = TV_L1_Denoising(IBn,lamb,1,0.5)\n",
    "print('PSNR(IB,IRef):',PSNR(IB,I))\n",
    "print('PSNR(Irec,IRef):',PSNR(Irec,I))\n",
    "\n",
    "\n",
    "pn.Row(hv.Image(I).opts(**optionsGray).relabel('Ref'),hv.Image(IBn).opts(**optionsGray).relabel('Bruité'),hv.Image(Irec).opts(**optionsGray).relabel('Débruitée'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## The Huber-ROF model\n",
    "\n",
    "We replace the $L^1$ norm in the total variation term by the Huber-norm:\n",
    "\n",
    "$$|x|_\\alpha = \\begin{cases}\n",
    "    \\frac{|x|^2}{2\\alpha} & \\textrm{if} \\;\\; |x| \\leq \\alpha \\\\\n",
    "    |x| -\\frac{\\alpha}{2} & \\textrm{if} \\;\\; |x| > \\alpha\n",
    "\\end{cases}$$\n",
    "\n",
    "where $\\alpha \\gt 0$ is a small parameter defining the tradeoff between quadratic regularization (for small values) and total variation regularization (for larger values).\n",
    "\n",
    "The primal-dual formulation of the Huber-ROF model is thus given by\n",
    "\n",
    "$$\\min_{u\\in X} \\max_{p\\in Y} -\\langle u, \\textrm{div}p \\rangle_X +\\frac{\\lambda}{2}||u-g||_2^2 -\\delta_P(p) -\\frac{\\alpha}{2}||p||_2^2$$\n",
    "\n",
    "Consequently, the resolvent operator with respect to $F^*$ is given by the pointwise operations\n",
    "\n",
    "$$p = (I -\\sigma\\partial F^*)^{-1}(\\tilde{p}) \\iff p_{i,j}= \\frac{\\frac{\\tilde{p}_{i,j}}{1+\\sigma\\alpha}}{\\textrm{max}(1,|\\frac{\\tilde{p}_{i,j}}{1+\\sigma\\alpha}|)}$$\n",
    "\n",
    "Note that the Huber-ROF model is uniformly convex in $G(u)$ and $F^*(p)$, with convexity parameters $\\lambda$ and $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def Huber_ROF_Denoising(I,lamb,sigma,tau,alpha,theta = 1,Niter=10000):\n",
    "    n,m = np.shape(I)\n",
    "    \n",
    "    # Opérateurs proximaux\n",
    "    def prox_sig_F_ad(p,sigma,alpha):\n",
    "        den = (p/(1+sigma*alpha))**2\n",
    "        den = (den[:,:,0] + den[:,:,1])**0.5\n",
    "        den = np.where(den < 1, 1, den)\n",
    "        den_2 = np.zeros(np.shape(p))\n",
    "        den_2[:,:,0] = den\n",
    "        den_2[:,:,1] = den\n",
    "        res = (p/(1+sigma*alpha))/den_2\n",
    "        return res\n",
    "\n",
    "    def prox_tau_G(u,g,lam,tau):\n",
    "        res = (u + lam*tau*g)/(1+lam*tau)\n",
    "        return res\n",
    "    \n",
    "    #Initialisation\n",
    "    u = np.zeros((m,n))\n",
    "    p = np.zeros((m,n,2)) \n",
    "    u_bar = np.copy(u)\n",
    "    \n",
    "    it = 0\n",
    "    err = 1\n",
    "    err_iter = []\n",
    "    \n",
    "    while it < Niter and err > 1e-10 :\n",
    "        \n",
    "        p = prox_sig_F_ad(p+sigma*grad(u_bar),sigma,alpha)\n",
    "        u_prev = np.copy(u)\n",
    "        u = prox_tau_G(u-tau*grad_ad(p),I,lamb,tau)\n",
    "        u_bar_prev = np.copy(u_bar)\n",
    "        u_bar = u + theta*(u -u_prev)\n",
    "        \n",
    "        err = npl.norm(u_bar - u_bar_prev)\n",
    "        \n",
    "        it += 1\n",
    "        err_iter += [err]\n",
    "        \n",
    "    return u_bar, err_iter, it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "I = imagesRef['Lenna'].astype('uint8')\n",
    "seednoise = 1\n",
    "mu = 15\n",
    "IB = Noise(I,seednoise,mu)\n",
    "\n",
    "lamb = 0.07 #5\n",
    "alpha = 0.05 #0.05\n",
    "L = 3\n",
    "mu = 2*np.sqrt(alpha*lamb)/L\n",
    "print(f\"mu = {mu}\")\n",
    "\n",
    "sigma = 0.2\n",
    "tau = 0.5\n",
    "print(f\"sigma*tau = {sigma*tau}\")\n",
    "print(f\"1/L**2 = {1/L**2}\")\n",
    "\n",
    "Irec, error, it = Huber_ROF_Denoising(IB,lamb,sigma,tau,alpha)\n",
    "print('PSNR(IB,IRef):',PSNR(IB,I))\n",
    "print('PSNR(Irec,IRef):',PSNR(Irec,I))\n",
    "\n",
    "IrecCP,err,it = ChambollPock_Denoising(IB,0.09,0.25,0.5,1,100)\n",
    "\n",
    "pn.Row(hv.Image(IB).opts(**optionsGray).relabel('Bruité'),hv.Image(Irec).opts(**optionsGray).relabel('Débruitée Huber-ROF'),hv.Image(IrecCP).opts(**optionsGray).relabel('Débruitée ROF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "lamb = 0.08 #5\n",
    "alpha = 0.05 #0.05\n",
    "L = 3\n",
    "mu = 2*np.sqrt(alpha*lamb)/L\n",
    "print(f\"mu = {mu}\")\n",
    "\n",
    "sigma = 0.2\n",
    "tau = 0.5\n",
    "print(f\"sigma*tau = {sigma*tau}\")\n",
    "print(f\"1/L**2 = {1/L**2}\")\n",
    "\n",
    "Irec, error, it = Huber_ROF_Denoising(IB,lamb,sigma,tau,alpha)\n",
    "print('PSNR(IB,IRef):',PSNR(IB,I))\n",
    "print('PSNR(Irec,IRef):',PSNR(Irec,I))\n",
    "plt.loglog()\n",
    "plt.plot(np.arange(it),error,color='black')\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel('iterations')\n",
    "plt.title(r'TV-L1:  $\\lambda = 1.5$')\n",
    "plt.show()\n",
    "pn.Row(hv.Image(I).opts(**optionsGray).relabel('Ref'),hv.Image(IB).opts(**optionsGray).relabel('Bruité'),hv.Image(Irec).opts(**optionsGray).relabel('Débruitée'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Gaussian kernel and Convolution\n",
    "\n",
    "Using the property of the Fourier transform applied to a convolution:\n",
    "$$\\mathcal{F}(k_A * u) = \\mathcal{F}(k_A) \\mathcal{F}(u)$$ \n",
    "\n",
    "The convolution operation can be efficiently computed using the fast Fourier transform:\n",
    "$$k_A * u = \\mathcal{F}^{-1}(\\mathcal{F}(k_A) \\mathcal{F}(u))$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def Gaussian2D(N,sigma):\n",
    "    x, y = np.meshgrid(np.linspace(-1,1,N), np.linspace(-1,1,N))\n",
    "    d2 = x**2 + y**2\n",
    "    g = np.exp(-( d2 / ( 2.0 * sigma**2)))\n",
    "    g2 = fftshift(g)\n",
    "    s = np.sum(g2)\n",
    "    g2 = g2/s\n",
    "    return g2\n",
    "\n",
    "def Convolution2D(I,kernel):\n",
    "    Iconvol=np.real(ifft2(fft2(I)*fft2(kernel)))\n",
    "    return Iconvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "I = imagesRef[\"Lenna\"].astype('uint8')\n",
    "kernel = Gaussian2D(256,0.01)\n",
    "Iconvol = Convolution2D(I,kernel)\n",
    "pn.Row(hv.Image(I).opts(**optionsGray).relabel('Référence'),hv.Image(Iconvol).opts(**optionsGray).relabel('Image Convoluée'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## The ROF model\n",
    "\n",
    "**Total variation based image deconvolution model** proposed by Rudin, Osher and Fatemi: <br>\n",
    "$$\\min_{ x} \\int_{\\Omega} | Du | + \\frac{\\lambda}{2} \\| Au - g \\|_2^{2}$$\n",
    "\n",
    "where $\\Omega \\in \\mathbb{R}^{d}$ is the $d$-dimensional image domain, $u \\in L^1(\\Omega)$ is the sought solution and $g \\in L^1(\\Omega)$ is the noisy input image and $A$ is a linear operator. In our case, $A$ is the convolution\n",
    "\n",
    "**In discrete setting** (dimension d=2)\n",
    "\n",
    "Total variation based image deconvolution model proposed by Rudin, Osher and Fatemi: <br>\n",
    "\n",
    "$$h^{2} \\min_{u \\in X} \\|\\nabla u \\|_1 + \\frac{\\lambda}{2} \\| Au - g \\|_2^{2}$$\n",
    "\n",
    "where $u \\in L^1(\\Omega)$ is the sought solution, $g \\in L^1(\\Omega)$ is the convolutionned input image and $A$ is the convolution with the point spread function (PSF).\n",
    "In this case, we use a Gaussian filter, but more generally the PSF is the response of an imaging system to a point source.\n",
    "\n",
    "$Au = k_A*u$ with $k_A$ the convolution kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "The **Primal-dual formulation of the ROF problem** is given by \n",
    "\n",
    "$$h^2 \\min_{u \\in X}  \\max_{p \\in Y} - \\langle u, \\text{div } p \\rangle_X + \\frac{\\lambda}{2} \\|Au-g\\|_2^{2} - \\delta_P(p)$$ \n",
    "where $Au$ can be written as a convolution\n",
    "$Au=k_A \\ast u$ where $k_A$ is the convolution kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "Operators: \n",
    "$$ p =(I+ \\sigma \\partial F^*)^{-1} (\\bar p) \\Leftrightarrow p_{i,j} = \\frac{ \\bar p_{i,j}}{\\max(1,| \\bar p_{i,j} |)}$$\n",
    "$$ u =(I+ \\tau \\partial G)^{-1} (\\bar u) = \\mathcal{F} ^{-1} \\left( \\frac{\\tau \\lambda \\mathcal{F}(g)\\mathcal{F}(k_A)^* + \\mathcal{F}(\\bar u)}{\\tau \\lambda \\mathcal{F}(k_A)^{2} +1}\\right) $$\n",
    "where $\\mathcal{F}(.)$ and $\\mathcal{F}^{-1}(.)$ denote the FFT and inverse FFT, respectively.\n",
    "According to the convolution theorem, the multiplication and division operators are understood pointwise in the above formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def prox_sig_F_ad(p):\n",
    "    norm = np.sqrt(p[:,:,0]**2 + p[:,:,1]**2)\n",
    "    norm = np.where(norm < 1, 1, norm)\n",
    "    res = p/norm[:,:,None]\n",
    "    return res\n",
    "\n",
    "def prox_tau_G(u, g_fft, kA_fft, lam, tau):\n",
    "    N = u.shape[0]\n",
    "    nom = tau*lam*g_fft*np.conj(kA_fft).T + fft2(u)\n",
    "    den = tau*lam*np.abs(kA_fft)**2 + 1\n",
    "    res = ifft2(nom/den)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "Chamboll Pock Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def ChambollPock(I, kA, lamb, sigma, tau, theta = 1, Niter=1000):\n",
    "    n,m = np.shape(I)\n",
    "    \n",
    "    # Initialisation with the blurred image\n",
    "    u = I.astype(\"float64\")\n",
    "    p = grad(u)\n",
    "\n",
    "    u_bar = np.copy(u)\n",
    "    \n",
    "    it = 0\n",
    "    err = 1\n",
    "    err_iter = []\n",
    "    \n",
    "    # Precomputing the fft of the convolution kernel and the blurred image\n",
    "    kA_fft = fft2(kA)\n",
    "    g_fft = fft2(I)\n",
    "\n",
    "    while it < Niter and err > 1e-10 :\n",
    "        p = prox_sig_F_ad(p + sigma*grad(u_bar))\n",
    "        u_prev = np.copy(u)\n",
    "        u = prox_tau_G(u-tau*grad_ad(p), g_fft, kA_fft, lamb, tau)\n",
    "        u_bar_prev = np.copy(u_bar)\n",
    "        u_bar = u + theta*(u - u_prev)\n",
    "        err = npl.norm(u_bar - u_bar_prev)\n",
    "        \n",
    "        it += 1\n",
    "        err_iter += [err]\n",
    "        \n",
    "    return np.real(u_bar), err_iter, it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "lamb = 1.\n",
    "sigma = 0.5\n",
    "tau = 0.25\n",
    "\n",
    "Ideconvol, erreur, Niter = ChambollPock(Iconvol, kernel, lamb, sigma, tau, Niter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "pn.Row(hv.Image(I).opts(**optionsGray).relabel('Référence'),hv.Image(Iconvol).opts(**optionsGray).relabel('Image Convoluée'),hv.Image(np.real(Ideconvol)).opts(**optionsGray).relabel('Image Déconvoluée'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class CPDeblurring(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Lenna\",objects=imagesRef.keys())\n",
    "    Niter = param.Integer(100,bounds=(1,1000))\n",
    "    lamb = param.Number(10,bounds=(0,100))\n",
    "    tau = param.Number(0.5,bounds=(0,10))\n",
    "    sigma = param.Number(0.25,bounds=(0,10))\n",
    "    blur = param.Number(0.01, bounds=(0.01,0.05), step=0.01)\n",
    "    \n",
    "    def view(self):\n",
    "        I = imagesRef[self.image].astype('uint8')\n",
    "        kernel = Gaussian2D(256,self.blur)\n",
    "        IConvol = Convolution2D(I,kernel).astype('uint8')\n",
    "        IDeconvol,err,it=ChambollPock(IConvol,kernel,self.lamb,self.sigma,self.tau,1,self.Niter)\n",
    "        \n",
    "        IDeconvol = np.real(IDeconvol).astype('uint8')\n",
    "        \n",
    "        Image1 = hv.Image(I).opts(**optionsGray).relabel('Référence')\n",
    "        Image2 = hv.Image(IConvol).opts(**optionsGray).relabel('Image convoluée')\n",
    "        Image3 = hv.Image(IDeconvol).opts(**optionsGray).relabel('Image déconvoluée')\n",
    "        return pn.Row(Image1,Image2,Image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "cpdeblurring = CPDeblurring()\n",
    "pn.Row(cpdeblurring.param,cpdeblurring.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "# Image inpainting\n",
    "\n",
    "The reconstruction model is given by the following problem inspired by ROF:\n",
    "\n",
    "$$\\min_{u\\in X} ||\\Phi u||_1 + \\frac{\\lambda}{2}\\sum_{i,j\\in D\\backslash I}(u_{i,j} -g_{i,j})^2$$\n",
    "\n",
    "where $D = \\{(i,j),1\\leq i \\leq M, 1\\leq j \\leq N\\}$ is the set of indices of the image domain and $I\\subset D$ denotes the set of indices of the inpainting domain.\n",
    "\n",
    "We can then rearrange the problem as:\n",
    "\n",
    "$$\\min_{u\\in X} \\max_{c\\in W} \\langle \\Phi u, c\\rangle   + \\frac{\\lambda}{2}\\sum_{i,j\\in D\\backslash I}(u_{i,j} -g_{i,j})^2 - \\delta_C(c)$$\n",
    "\n",
    "where $C$ is the convex set defined as\n",
    "\n",
    "$C = \\{ c\\in W: ||c||_{\\infty}\\leq 1\\}, \\;\\;\\; ||c||_{\\infty} = \\max_k |c_k|$\n",
    "\n",
    "We find that\n",
    "\n",
    "$$c = (I+\\sigma\\partial F^*)^{-1}(\\tilde{c}) \\iff c_k = \\frac{\\tilde{c}_k}{max(1,|\\tilde{c}_k|)}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$u = (I+\\tau\\partial G)^{-1}(\\tilde{u}) \\iff u_{i,j} = \\begin{cases} \n",
    "      \\tilde{u}_{i,j} & \\textrm{if} \\;\\; (i,j) \\in I \\\\\n",
    "      \\frac{\\tilde{u}_{i,j} + \\tau\\lambda g_{i,j}}{1 + \\tau\\lambda} & \\textrm{else} \\\\\n",
    "   \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "We start by removing 80% of the image's lines at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "h,w = im1.shape\n",
    "nbr_blanck_lines = int(h*0.8)\n",
    "samp = sample(list(np.arange(h)),nbr_blanck_lines)\n",
    "\n",
    "I = imagesRef['Lenna'].astype('uint8')\n",
    "im_blanck = im1\n",
    "im_blanck[samp,:] = np.zeros((nbr_blanck_lines,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "pn.Row(hv.Image(I).opts(**optionsGray).relabel('Reference'),hv.Image(im_blanck).opts(**optionsGray).relabel('Altered Image'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "We define the two proximal operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def prox_sig_F_ad_Inpainting(p):\n",
    "    den = p**2\n",
    "    den = (den[:,:,0] + den[:,:,1])**0.5\n",
    "    den = np.where(den < 1, 1, den)\n",
    "    den_2 = np.zeros(np.shape(p))\n",
    "    den_2[:,:,0] = den\n",
    "    den_2[:,:,1] = den\n",
    "    res = p/den_2\n",
    "    return res\n",
    "\n",
    "def prox_tau_G_Inpainting(u,g,lam,tau,samp):\n",
    "    res = (u + lam*tau*g)/(1+lam*tau)\n",
    "    res[samp,:] = u[samp,:]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "We define the Chamboll Pock algorithm for our inpainting problem. This problem can only be solved using the standard form of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def ChambollPock_Inpainting(I,lamb,sigma,tau,samp,theta = 1,Niter=10000):\n",
    "    n,m = np.shape(I)\n",
    "    \n",
    "    #Initialisation (à revoir peut-être)\n",
    "    u = np.zeros((m,n)) \n",
    "    p = np.zeros((m,n,2)) \n",
    "    u_bar = np.copy(u)\n",
    "    \n",
    "    it = 0\n",
    "    err = 1\n",
    "    err_iter = []\n",
    "    \n",
    "    while it < Niter and err > 1e-10 :\n",
    "        p = prox_sig_F_ad_Inpainting(p+sigma*grad(u_bar))\n",
    "        u_prev = np.copy(u)\n",
    "        u = prox_tau_G_Inpainting(u-tau*grad_ad(p),I,lamb,tau,samp)\n",
    "        u_bar_prev = np.copy(u_bar)\n",
    "        u_bar = u + theta*(u -u_prev)\n",
    "        err = npl.norm(u_bar - u_bar_prev)\n",
    "        \n",
    "        \n",
    "        it += 1\n",
    "        err_iter += [err]\n",
    "        \n",
    "    return u_bar, err_iter, it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "Irec_inp, error_inp, it_inp = ChambollPock_Inpainting(im_blanck,8,0.7,0.7,samp)\n",
    "print('PSNR(IB,IRef):',PSNR(im_blanck,I))\n",
    "print('PSNR(Irec,IRef):',PSNR(Irec_inp,I))\n",
    "plt.loglog()\n",
    "plt.plot(np.arange(it_inp),error_inp,color='black')\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel('iterations')\n",
    "plt.title(r'Inpainting:  $\\lambda = 8.0$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "pn.Row(hv.Image(I).opts(**optionsGray).relabel('Reference'),hv.Image(im_blanck).opts(**optionsGray).relabel('Altered Image'),hv.Image(Irec_inp).opts(**optionsGray).relabel('Reconstructed Image'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [
    {
     "name": "holoviews",
     "source": "PIP",
     "version": "1.14.7a7"
    }
   ],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
